# CrewAI Enterprise Deployment Requirements

> **Purpose**: This document outlines the critical requirements and best practices for successfully deploying CrewAI projects to CrewAI Enterprise. Use this as a checklist and reference guide to ensure your project structure, imports, and configurations align with deployment requirements.

---

## Table of Contents

1. [Project Structure Requirements](#1-project-structure-requirements)
2. [Package Configuration (pyproject.toml)](#2-package-configuration-pyprojecttoml)
3. [Import Architecture](#3-import-architecture)
4. [Module Organization & __init__.py Files](#4-module-organization--__init__py-files)
5. [Main Entry Point (main.py)](#5-main-entry-point-mainpy)
6. [Agent Implementation](#6-agent-implementation)
7. [Crew Implementation](#7-crew-implementation)
8. [Custom Tool Development](#8-custom-tool-development)
9. [Type Definitions & Pydantic Models](#9-type-definitions--pydantic-models)
10. [Services & Utilities](#10-services--utilities)
11. [YAML Configuration](#11-yaml-configuration)
12. [Environment Variables](#12-environment-variables)
13. [Flow Implementation](#13-flow-implementation)
14. [Dynamic Registries](#14-dynamic-registries)
15. [Common Deployment Failures](#15-common-deployment-failures)
16. [Pre-Deployment Checklist](#16-pre-deployment-checklist)

---

## 1. Project Structure Requirements

### Required Directory Structure

```
project_root/
├── pyproject.toml          # REQUIRED: Package configuration
├── README.md               # REQUIRED: Project documentation
├── .env                    # REQUIRED: Environment variables (DO NOT COMMIT)
├── .gitignore             # REQUIRED: Git ignore rules
├── uv.lock                # Generated by uv
├── knowledge/             # OPTIONAL: Knowledge base files
│   └── docs/
└── src/                   # REQUIRED: Source code directory
    └── package_name/      # MUST match [project.name] in pyproject.toml
        ├── __init__.py    # REQUIRED: Usually empty
        ├── main.py        # REQUIRED: Entry point
        ├── agents/        # OPTIONAL but recommended
        │   ├── __init__.py
        │   └── agent_name.py
        ├── crews/         # OPTIONAL: For multi-agent crews
        │   ├── __init__.py
        │   └── crew_name/
        │       ├── crew.py
        │       └── config/
        │           ├── agents.yaml
        │           └── tasks.yaml
        ├── tools/         # OPTIONAL: Custom tools
        │   ├── __init__.py
        │   └── tool_name.py
        ├── types/         # RECOMMENDED: Type definitions
        │   ├── __init__.py
        │   ├── flow_state.py
        │   └── output_models.py
        ├── services/      # OPTIONAL: Business logic services
        │   ├── __init__.py
        │   └── service_name.py
        ├── utils/         # OPTIONAL: Utility functions
        │   ├── __init__.py
        │   └── utility_name.py
        └── registries/    # OPTIONAL: Dynamic configuration
            ├── __init__.py
            └── registry_name.py
```

### Critical Rules

1. **Package name consistency**: The directory under `src/` MUST match the `name` field in `[project]` section of `pyproject.toml`
2. **Every directory needs __init__.py**: All directories under `src/package_name/` must contain an `__init__.py` file
3. **Use src/ layout**: Always use the `src/` directory structure for proper packaging
4. **Relative config paths**: YAML configs in crews are relative to the crew.py file location

---

## 2. Package Configuration (pyproject.toml)

### Minimal Required Configuration

```toml
[project]
name = "package_name"                    # MUST match src/package_name/
version = "0.1.0"
description = "Project description using crewAI"
authors = [{ name = "Author Name", email = "email@example.com" }]
requires-python = ">=3.10,<3.14"        # CrewAI requirement
dependencies = [
    "crewai[google-genai,tools]==1.4.1", # Pin specific version
    # Add other dependencies here
]

[project.scripts]
kickoff = "package_name.main:kickoff"    # Entry point for execution
run_crew = "package_name.main:kickoff"   # Alias
plot = "package_name.main:plot"          # Flow visualization

[build-system]
requires = ["hatchling"]                 # REQUIRED
build-backend = "hatchling.build"        # REQUIRED

[tool.hatch.metadata]
allow-direct-references = true           # REQUIRED for some dependencies

[tool.crewai]
type = "flow"                            # or "crew"
```

### Key Requirements

- **Build system**: Must use `hatchling` as build backend
- **Python version**: Must be `>=3.10,<3.14`
- **CrewAI pinning**: Pin exact CrewAI version (e.g., `==1.4.1`)
- **Entry points**: Define at least `kickoff` and `plot` commands
- **Package name**: Must match directory structure exactly

---

## 3. Import Architecture

### Absolute Import Pattern (REQUIRED)

**✅ CORRECT - Use absolute imports everywhere:**

```python
# In main.py
from package_name.agents import AgentClass
from package_name.crews import CrewClass
from package_name.types import StateModel
from package_name.tools import ToolClass

# In agents/agent_file.py
from package_name.types import OutputModel
from package_name.tools import ToolClass

# In crews/crew_name/crew.py
from package_name.tools import ToolClass
from package_name.types import OutputModel

# In tools/tool_file.py
from package_name.types import FilterModel
```

**❌ WRONG - Never use relative imports:**

```python
# These will fail in deployment
from .agents import AgentClass        # NO
from ..types import StateModel        # NO
from agents import AgentClass         # NO
```

### Import from CrewAI

```python
# Standard CrewAI imports
from crewai import Agent, Crew, Task, LLM
from crewai.flow import Flow, listen, router, start, or_, persist
from crewai.project import CrewBase, agent, crew, task
from crewai.tasks.task_output import TaskOutput
from crewai.agents.agent_builder.base_agent import BaseAgent

# CrewAI Tools
from crewai_tools import (
    SerperDevTool,
    WebsiteSearchTool,
    QdrantVectorSearchTool,
    InvokeCrewAIAutomationTool,
)
```

---

## 4. Module Organization & __init__.py Files

### Purpose of __init__.py

The `__init__.py` file serves three purposes:
1. Marks the directory as a Python package
2. Controls what gets imported with `from package import *`
3. Provides a clean import interface

### Pattern for __init__.py Files

**agents/__init__.py:**
```python
from .agent_file1 import AgentClass1
from .agent_file2 import AgentClass2

__all__ = ["AgentClass1", "AgentClass2"]
```

**crews/__init__.py:**
```python
from .crew_name1.crew import CrewClass1
from .crew_name2.crew import CrewClass2

__all__ = ["CrewClass1", "CrewClass2"]
```

**tools/__init__.py:**
```python
from .tool_file1 import ToolClass1
from .tool_file2 import ToolClass2

__all__ = ["ToolClass1", "ToolClass2"]
```

**types/__init__.py:**
```python
from .flow_state import FlowState
from .output_model1 import OutputModel1
from .output_model2 import OutputModel2

__all__ = ["FlowState", "OutputModel1", "OutputModel2"]
```

**services/__init__.py:**
```python
from .service_file import ServiceClass

__all__ = ["ServiceClass"]
```

**Package root __init__.py (src/package_name/__init__.py):**
```python
# Usually left empty
```

---

## 5. Main Entry Point (main.py)

### Complete main.py Template

```python
#!/usr/bin/env python

from crewai.flow import Flow, listen, router, start, or_, persist

# Import from your package using absolute paths
from package_name.agents import Agent1, Agent2
from package_name.crews import Crew1, Crew2
from package_name.services import ServiceClass
from package_name.types import FlowState


# Optional: Use @persist() for state persistence between runs
@persist()
class ProjectFlow(Flow[FlowState]):
    """Main flow orchestrating the project logic"""
    
    def __init__(self):
        super().__init__(tracing=True)

    @start()
    def initialize(self):
        """Entry point - initialize services and dependencies"""
        self.service = ServiceClass()
        print("Flow initialized")

    @router(initialize)
    def route_logic(self):
        """Route based on state - return value determines next path"""
        return self.state.route_type

    @listen("route_value1")
    def handle_route1(self):
        """Handle first route option"""
        result = Agent1().execute(self.state.input_data)
        self.state.result = result.pydantic.output

    @listen("route_value2")
    def handle_route2(self):
        """Handle second route option"""
        result = Crew1().crew().kickoff(
            inputs={"question": self.state.input_data}
        )
        self.state.result = result.pydantic.answer

    @listen(or_(handle_route1, handle_route2))
    def finalize(self):
        """Final step - return results"""
        return {"result": self.state.result}


def kickoff():
    """
    Entry point for running the flow.
    This function is called when running 'kickoff' command.
    """
    ProjectFlow().kickoff(
        inputs={
            "route_type": "route_value1",
            "input_data": "test input"
        }
    )


def plot():
    """
    Entry point for visualizing the flow.
    This function is called when running 'plot' command.
    """
    ProjectFlow().plot()


if __name__ == "__main__":
    kickoff()
```

### Critical Requirements

1. **Shebang line**: Include `#!/usr/bin/env python` at top
2. **Absolute imports**: Use `from package_name.module import Class`
3. **Entry functions**: Define `kickoff()` and `plot()` at minimum
4. **Flow typing**: Use `Flow[FlowState]` generic typing
5. **Main guard**: Include `if __name__ == "__main__"` block

---

## 6. Agent Implementation

### Standalone Agent Pattern

```python
# File: agents/classification_agent.py

from crewai import Agent
from package_name.types import ClassificationOutput


class ClassificationAgent:
    """Agent for classifying input data"""
    
    def classify(self, input_text: str):
        """
        Main entry method for classification
        
        Args:
            input_text: Text to classify
            
        Returns:
            Result with pydantic output
        """
        return self._agent().kickoff(
            self._prompt(input_text),
            response_format=ClassificationOutput
        )

    def _agent(self) -> Agent:
        """Create and configure the agent"""
        return Agent(
            role="Classification Specialist",
            goal="Accurately classify input text into predefined categories",
            backstory="""
                You are an expert in text classification with years of experience
                in natural language processing and categorization systems.
            """,
            llm="gemini/gemini-2.5-flash",
            verbose=True,
        )

    def _prompt(self, input_text: str) -> str:
        """Generate prompt for the agent"""
        return f"""
            Analyze and classify the following text:
            
            Text: {input_text}
            
            Provide your classification with reasoning.
        """
```

### Agent with Tools

```python
# File: agents/research_agent.py

from crewai import Agent
from package_name.tools import SearchTool, AnalysisTool
from package_name.types import ResearchOutput


class ResearchAgent:
    """Agent for conducting research using tools"""
    
    def research(self, topic: str):
        return self._agent().kickoff(
            self._prompt(topic),
            response_format=ResearchOutput
        )

    def _agent(self) -> Agent:
        return Agent(
            role="Research Analyst",
            goal="Conduct thorough research on given topics",
            backstory="Expert researcher with access to search tools",
            llm="gpt-4.1",
            tools=[
                SearchTool().tool(),      # Call .tool() method
                AnalysisTool().tool(),    # Call .tool() method
            ],
            verbose=True,
        )

    def _prompt(self, topic: str) -> str:
        return f"Research the following topic thoroughly: {topic}"
```

### Key Requirements

1. **Public method**: Main entry method (e.g., `classify()`, `research()`)
2. **Private _agent()**: Returns configured Agent instance
3. **Private _prompt()**: Generates prompts dynamically
4. **Tools**: Call `.tool()` method when passing tools
5. **response_format**: Use Pydantic models for structured output
6. **Access results**: Use `.pydantic.field_name` to access structured output

---

## 7. Crew Implementation

### Crew with @CrewBase Decorator

```python
# File: crews/analysis_crew/crew.py

from typing import List
from crewai import Agent, Crew, Process, Task
from crewai.agents.agent_builder.base_agent import BaseAgent
from crewai.project import CrewBase, agent, crew, task
from crewai.tasks.task_output import TaskOutput

from package_name.tools import CustomTool
from package_name.types import AnalysisOutput


# Optional: Condition function for conditional tasks
def is_valid(output: TaskOutput) -> bool:
    """Check if previous task output meets criteria"""
    return output.pydantic.is_valid


@CrewBase
class AnalysisCrew:
    """Crew for performing analysis tasks"""
    
    agents: List[BaseAgent]  # REQUIRED
    tasks: List[Task]        # REQUIRED

    # Paths relative to this file
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    def __init__(self, custom_parameter: str):
        """Initialize with custom parameters"""
        self.custom_parameter = custom_parameter

    @agent
    def analyst_agent(self) -> Agent:
        """Define analyst agent from YAML config"""
        return Agent(
            config=self.agents_config["analyst"],
            tools=[
                CustomTool(param=self.custom_parameter).tool()
            ]
        )

    @agent
    def reviewer_agent(self) -> Agent:
        """Define reviewer agent from YAML config"""
        return Agent(config=self.agents_config["reviewer"])

    @task
    def analyze_task(self) -> Task:
        """Define analysis task from YAML config"""
        return Task(
            config=self.tasks_config["analyze"],
            output_pydantic=AnalysisOutput
        )

    @task
    def review_task(self) -> Task:
        """Define review task from YAML config"""
        return Task(
            config=self.tasks_config["review"],
            output_pydantic=AnalysisOutput
        )

    @crew
    def crew(self) -> Crew:
        """Assemble the crew"""
        return Crew(
            agents=self.agents,  # Auto-populated from @agent methods
            tasks=self.tasks,    # Auto-populated from @task methods
            process=Process.sequential,
            verbose=True,
        )
```

### Using the Crew

```python
# In main.py or flow
from package_name.crews import AnalysisCrew

# Initialize with parameters
crew_instance = AnalysisCrew(custom_parameter="value")

# Execute the crew
result = crew_instance.crew().kickoff(
    inputs={"question": "What needs analysis?"}
)

# Access structured output
answer = result.pydantic.answer
```

### Key Requirements

1. **@CrewBase decorator**: Required on crew class
2. **Type hints**: `agents: List[BaseAgent]` and `tasks: List[Task]`
3. **Config paths**: Relative to crew.py file location
4. **@agent decorator**: For agent definition methods
5. **@task decorator**: For task definition methods
6. **@crew decorator**: For crew assembly method
7. **Tools**: Call `.tool()` method when passing to agents
8. **Access results**: Use `.pydantic.field_name` for structured output

---

## 8. Custom Tool Development

### Wrapper Tool Pattern

Most custom tools wrap existing CrewAI tools with custom configuration:

```python
# File: tools/search_tool.py

import os
from crewai_tools import SerperDevTool


class SearchTool:
    """Wrapper for search functionality"""
    
    def __init__(self, num_results: int = 5):
        self.num_results = num_results

    def tool(self) -> SerperDevTool:
        """
        Returns configured tool instance
        
        CRITICAL: This method MUST be called when passing to agents
        """
        return SerperDevTool(
            api_key=os.getenv("SERPER_API_KEY"),
            n_results=self.num_results
        )
```

### Complex Tool with Custom Logic

```python
# File: tools/vector_search_tool.py

import os
from crewai_tools import QdrantVectorSearchTool
from qdrant_client.http.models import FieldCondition, Filter, MatchValue

from package_name.types import SearchFilter


class VectorSearchTool:
    """Vector database search with filtering"""
    
    def __init__(
        self,
        collection_name: str,
        search_filter: SearchFilter | None = None
    ):
        self.collection_name = collection_name
        self.search_filter = search_filter

    def tool(self) -> QdrantVectorSearchTool:
        """Returns configured Qdrant search tool"""
        return QdrantVectorSearchTool(
            qdrant_config={
                "qdrant_url": os.getenv("QDRANT_URL"),
                "qdrant_api_key": os.getenv("QDRANT_API_KEY"),
                "collection_name": self.collection_name,
                "limit": 5,
                "filter": self._build_filter(),
            }
        )

    def _build_filter(self) -> Filter:
        """Build Qdrant filter from search filter"""
        if not self.search_filter:
            return None
        
        return Filter(
            must=self._build_conditions(self.search_filter.must),
            must_not=self._build_conditions(self.search_filter.must_not),
        )

    def _build_conditions(self, conditions) -> list[FieldCondition]:
        """Convert filter conditions to Qdrant format"""
        if conditions is None:
            return None
        
        return [
            FieldCondition(
                key=condition.key,
                match=MatchValue(value=condition.value)
            )
            for condition in conditions
        ]
```

### Using Tools in Agents

```python
# In agent definition
from package_name.tools import SearchTool, VectorSearchTool

def _agent(self) -> Agent:
    return Agent(
        role="Researcher",
        goal="Research topics",
        backstory="Expert researcher",
        tools=[
            SearchTool(num_results=10).tool(),     # Call .tool() method
            VectorSearchTool(
                collection_name="my_collection"
            ).tool(),                               # Call .tool() method
        ]
    )
```

### Key Requirements

1. **Wrapper class**: Create a class that wraps the CrewAI tool
2. **.tool() method**: Must return the actual tool instance
3. **Always call .tool()**: When passing to agents, call `.tool()`
4. **Environment variables**: Use `os.getenv()` for API keys
5. **Type hints**: Use proper type hints for parameters

---

## 9. Type Definitions & Pydantic Models

### Flow State Model

```python
# File: types/flow_state.py

from typing import List, Optional
from pydantic import BaseModel, Field, model_validator


class FlowState(BaseModel):
    """
    State model for flow execution
    
    This model represents the state that flows through your CrewAI Flow.
    It should contain all inputs, intermediate results, and outputs.
    """
    
    # Input fields
    run_type: str = Field(default="default", description="Type of execution")
    input_data: Optional[str] = Field(None, description="Input data for processing")
    
    # Intermediate fields
    classification: Optional[str] = None
    
    # Output fields
    result: Optional[str] = None
    
    @model_validator(mode="after")
    def validate_requirements(self):
        """Custom validation logic"""
        if self.run_type == "special" and not self.input_data:
            raise ValueError("input_data required for special run_type")
        return self
```

### Output Models for Agents

```python
# File: types/agent_outputs.py

from typing import List
from pydantic import BaseModel, Field


class ClassificationOutput(BaseModel):
    """Output schema for classification agent"""
    category: str = Field(..., description="Classified category")
    confidence: float = Field(..., description="Confidence score (0-1)")
    reasoning: str = Field(..., description="Reasoning for classification")


class AnalysisOutput(BaseModel):
    """Output schema for analysis tasks"""
    answer: str = Field(..., description="The analyzed answer")
    sources: List[str] = Field(default=[], description="Source references")
    metadata: dict = Field(default={}, description="Additional metadata")


class ValidationOutput(BaseModel):
    """Output schema for validation tasks"""
    is_valid: bool = Field(..., description="Whether input is valid")
    message: str = Field(..., description="Validation message")
```

### Filter/Configuration Models

```python
# File: types/filter_models.py

from typing import List, Optional
from pydantic import BaseModel


class FilterCondition(BaseModel):
    """Individual filter condition"""
    key: str
    value: str


class SearchFilter(BaseModel):
    """Search filter configuration"""
    must: Optional[List[FilterCondition]] = None
    must_not: Optional[List[FilterCondition]] = None
    should: Optional[List[FilterCondition]] = None
```

### Key Requirements

1. **Inherit from BaseModel**: All models must inherit from `pydantic.BaseModel`
2. **Field descriptions**: Use `Field(..., description="...")` for documentation
3. **Type hints**: Always include proper type hints
4. **Validators**: Use `@model_validator` for custom validation
5. **Access in code**: Use `.pydantic.field_name` to access from agent results

---

## 10. Services & Utilities

### Service Pattern

```python
# File: services/data_service.py

import os
import json
from pathlib import Path
from typing import List

from package_name.types import DataModel
from package_name.utils import ProcessingUtil


class DataService:
    """Service for data operations"""
    
    # Class-level configuration from environment
    _API_KEY = os.getenv("API_KEY")
    _API_URL = os.getenv("API_URL")
    _BATCH_SIZE = int(os.getenv("BATCH_SIZE", "10"))

    def __init__(self):
        """Initialize service with dependencies"""
        self._processing_util = ProcessingUtil()
        self._cache = []
        
        # Validate required environment variables
        if not self._API_KEY:
            raise ValueError("API_KEY environment variable required")

    @property
    def cache_size(self) -> int:
        """Property for accessing cache size"""
        return len(self._cache)

    def load_data(self, source: str) -> List[DataModel]:
        """
        Load data from source
        
        Args:
            source: Path or URL to data source
            
        Returns:
            List of processed data models
        """
        raw_data = self._fetch_data(source)
        return self._process_data(raw_data)

    def process_batch(self, items: List[DataModel]) -> List[DataModel]:
        """Process items in batches"""
        results = []
        for i in range(0, len(items), self._BATCH_SIZE):
            batch = items[i:i + self._BATCH_SIZE]
            results.extend(self._process_batch_internal(batch))
        return results

    def _fetch_data(self, source: str) -> dict:
        """Internal method for fetching data"""
        # Implementation
        pass

    def _process_data(self, raw_data: dict) -> List[DataModel]:
        """Internal method for processing data"""
        # Implementation
        pass

    def _process_batch_internal(self, batch: List[DataModel]):
        """Internal batch processing"""
        # Implementation
        pass
```

### Utility Pattern

```python
# File: utils/text_processor.py

import os
from typing import List
import tiktoken

from package_name.types import ProcessingMode


PRESETS = {
    ProcessingMode.FAST: {"chunk_size": 512, "overlap": 0.25},
    ProcessingMode.ACCURATE: {"chunk_size": 2048, "overlap": 0.10},
}


class TextProcessor:
    """Utility for text processing operations"""
    
    def __init__(
        self,
        mode: ProcessingMode = ProcessingMode.FAST,
        *,
        chunk_size: int | None = None,
        overlap: float | None = None,
        model: str = os.getenv("EMBEDDING_MODEL", "text-embedding-3-large"),
    ):
        """
        Initialize text processor
        
        Args:
            mode: Processing mode (FAST or ACCURATE)
            chunk_size: Override chunk size
            overlap: Override overlap ratio
            model: Model name for token counting
        """
        self.model = model
        
        # Apply preset or custom settings
        if mode == ProcessingMode.CUSTOM:
            if chunk_size is None or overlap is None:
                raise ValueError("Custom mode requires chunk_size and overlap")
            self.chunk_size = chunk_size
            self.overlap = overlap
        else:
            preset = PRESETS[mode]
            self.chunk_size = chunk_size or preset["chunk_size"]
            self.overlap = overlap or preset["overlap"]
        
        # Validate parameters
        if not (0.0 <= self.overlap < 1.0):
            raise ValueError("overlap must be in [0.0, 1.0)")
        if self.chunk_size <= 0:
            raise ValueError("chunk_size must be > 0")

    def process(self, text: str) -> List[str]:
        """
        Process text into chunks
        
        Args:
            text: Input text to process
            
        Returns:
            List of text chunks
        """
        # Implementation
        pass

    def count_tokens(self, text: str) -> int:
        """Count tokens in text"""
        return len(tiktoken.encoding_for_model(self.model).encode(text))
```

### Key Requirements

1. **Class-level config**: Load environment variables at class level
2. **Public methods**: Main API methods (no underscore prefix)
3. **Private methods**: Internal methods (underscore prefix)
4. **Properties**: Use `@property` for computed attributes
5. **Dependencies**: Import other modules using absolute paths
6. **Validation**: Validate required configuration in `__init__`

---

## 11. YAML Configuration

### Agents Configuration (agents.yaml)

```yaml
# File: crews/crew_name/config/agents.yaml

analyst:
  role: >
    Senior Data Analyst
  goal: >
    Analyze data thoroughly and provide actionable insights based on
    the information available in the knowledge base
  backstory: >
    You are an experienced data analyst with over 10 years of experience
    in analyzing complex datasets. You excel at finding patterns and
    extracting meaningful insights from data. Your analytical skills
    are complemented by your ability to communicate findings clearly.
  llm: gemini/gemini-2.5-flash

reviewer:
  role: >
    Quality Assurance Specialist
  goal: >
    Review analysis results for accuracy, completeness, and clarity
  backstory: >
    You are a meticulous quality assurance specialist who ensures
    that all analysis meets high standards of accuracy and clarity.
  llm: gpt-4.1
  verbose: true
```

### Tasks Configuration (tasks.yaml)

```yaml
# File: crews/crew_name/config/tasks.yaml

analyze:
  description: >
    Analyze the provided input data to generate insights.
    
    Input data: "{input_data}"
    
    GUIDELINES:
    1. Review all aspects of the input data
    2. Identify key patterns and trends
    3. Generate actionable insights
    4. Provide clear reasoning for conclusions
    
    Important: Be thorough and accurate in your analysis.
  expected_output: >
    A comprehensive analysis report with:
    - Key findings
    - Supporting evidence
    - Actionable recommendations
  agent: analyst

review:
  description: >
    Review the analysis for quality and accuracy.
    
    Validation criteria:
    - Accuracy of conclusions
    - Completeness of analysis
    - Clarity of recommendations
  expected_output: >
    A validation report confirming the analysis quality
  agent: reviewer
  context:
    - analyze  # This task depends on the analyze task
```

### Loading Configuration in Crews

```python
@CrewBase
class CrewName:
    # Paths are RELATIVE to the crew.py file
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"
    
    @agent
    def agent_name(self) -> Agent:
        # Access config by key matching YAML
        return Agent(config=self.agents_config["analyst"])
    
    @task
    def task_name(self) -> Task:
        # Access config by key matching YAML
        return Task(config=self.tasks_config["analyze"])
```

### Key Requirements

1. **Indentation**: Use spaces (2 spaces), never tabs
2. **Multi-line strings**: Use `>` for folded text, `|` for literal
3. **Key matching**: YAML keys must match config access in Python
4. **Agent reference**: Tasks must reference valid agent keys
5. **Context**: Use `context` to specify task dependencies
6. **Relative paths**: Config paths in crew are relative to crew.py file

---

## 12. Environment Variables

### .env File Structure

```env
# API Keys
OPENAI_API_KEY=sk-proj-...
GOOGLE_API_KEY=AIza...
SERPER_API_KEY=...

# Database / Vector Store
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=...
QDRANT_COLLECTION_PREFIX=your_prefix

# Model Configuration
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gemini/gemini-2.5-flash

# Processing Configuration
BATCH_SIZE=50
UPLOAD_BATCH_SIZE=100
MAX_CONCURRENT_REQUESTS=5

# API Endpoints (for automations)
AUTOMATION1_API_URL=https://api.example.com/v1/automation1
AUTOMATION1_BEARER_TOKEN=...
```

### Accessing Environment Variables

**Pattern 1: Class-level constants (Preferred)**

```python
import os

class ServiceClass:
    # Load at class definition time
    _API_KEY = os.getenv("API_KEY")
    _API_URL = os.getenv("API_URL")
    _BATCH_SIZE = int(os.getenv("BATCH_SIZE", "10"))  # With default
    
    def __init__(self):
        # Validate required variables
        if not self._API_KEY:
            raise ValueError("API_KEY environment variable is required")
```

**Pattern 2: Method-level (for tools)**

```python
import os

class CustomTool:
    def tool(self):
        return SomeTool(
            api_key=os.getenv("API_KEY"),
            url=os.getenv("API_URL")
        )
```

**Pattern 3: With python-dotenv (optional)**

```python
import os
from dotenv import load_dotenv

# Load .env file explicitly
load_dotenv()

# Then access as normal
api_key = os.getenv("API_KEY")
```

### Key Requirements

1. **Never commit .env**: Add to `.gitignore`
2. **Validation**: Check required variables exist
3. **Type conversion**: Cast to int/bool as needed
4. **Defaults**: Provide defaults for optional variables
5. **Naming**: Use UPPER_SNAKE_CASE for environment variables

---

## 13. Flow Implementation

### Flow Decorators

```python
from crewai.flow import Flow, listen, router, start, or_, persist

@persist()  # Optional: enables state persistence between runs
class ProjectFlow(Flow[FlowState]):
    
    @start()  # Marks the entry point
    def initialize(self):
        """First method to execute"""
        pass

    @router(initialize)  # Routes based on return value
    def determine_path(self):
        """Return value determines which @listen matches"""
        return self.state.route_key  # Returns "path1", "path2", etc.

    @listen("path1")  # Executes when route returns "path1"
    def handle_path1(self):
        """Handle first path"""
        pass

    @listen("path2")  # Executes when route returns "path2"
    def handle_path2(self):
        """Handle second path"""
        pass

    @listen(handle_path1)  # Executes after handle_path1 completes
    def continue_from_path1(self):
        """Next step after path 1"""
        pass

    @listen(or_(handle_path1, handle_path2))  # Executes after ANY complete
    def merge_paths(self):
        """Merge results from multiple paths"""
        pass
```

### State Access and Modification

```python
class ProjectFlow(Flow[FlowState]):
    
    @listen(some_method)
    def process_data(self):
        # Read from state
        input_value = self.state.input_field
        another_value = self.state.another_field
        
        # Call agent
        agent_result = AgentClass().execute(input_value)
        
        # Write to state
        self.state.output_field = agent_result.pydantic.answer
        
        # Call crew
        crew_result = CrewClass(param="value").crew().kickoff(
            inputs={"question": input_value}
        )
        
        # Write crew results to state
        self.state.crew_output = crew_result.pydantic.result
        
        # Return dictionary for next listener
        return {
            "agent_result": self.state.output_field,
            "crew_result": self.state.crew_output
        }
```

### Async Methods in Flows

```python
class ProjectFlow(Flow[FlowState]):
    
    @listen("async_route")
    async def async_method(self):
        """Async method for concurrent operations"""
        await self.service.async_operation()
        self.state.result = "completed"
```

### Key Requirements

1. **@start()**: Required on entry point method
2. **@router()**: Returns value to route execution
3. **@listen()**: Matches router return values or method references
4. **@persist()**: Optional for state persistence
5. **Flow[FlowState]**: Type hint with state model
6. **State access**: Use `self.state.field`
7. **Agent results**: Access via `.pydantic.field_name`

---

## 14. Dynamic Registries

### Registry Pattern for Dynamic Configuration

```python
# File: registries/automation_registry.py

import os
from pathlib import Path
from typing import List

import yaml
from crewai_tools import InvokeCrewAIAutomationTool
from pydantic import Field


class AutomationRegistry:
    """Registry for dynamically loaded automation tools"""
    
    @staticmethod
    def _load_automations_from_yaml() -> List[InvokeCrewAIAutomationTool]:
        """Load automation configurations from YAML file"""
        
        # Path relative to this file
        config_path = Path(__file__).parent / "config" / "automations.yaml"
        
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        
        automations = []
        for automation_config in config:
            # Build dynamic Pydantic Fields for inputs
            crew_inputs = {}
            for input_field in automation_config.get("inputs", []):
                field_name = input_field["name"]
                field_description = input_field["description"]
                field_required = input_field.get("required", True)
                
                if field_required:
                    crew_inputs[field_name] = Field(..., description=field_description)
                else:
                    crew_inputs[field_name] = Field(None, description=field_description)
            
            # Create automation tool instance
            automation = InvokeCrewAIAutomationTool(
                crew_api_url=os.getenv(automation_config["api_url_env"]),
                crew_bearer_token=os.getenv(automation_config["bearer_token_env"]),
                crew_name=automation_config["name"],
                crew_description=automation_config["description"],
                crew_inputs=crew_inputs,
            )
            automations.append(automation)
        
        return automations

    # Load at class definition time (called once when module loads)
    _automations = _load_automations_from_yaml.__func__()

    @classmethod
    def get_all(cls) -> List[InvokeCrewAIAutomationTool]:
        """Get all registered automations"""
        return cls._automations

    @classmethod
    def get_by_name(cls, name: str) -> InvokeCrewAIAutomationTool:
        """Get automation by name"""
        for automation in cls._automations:
            if automation.name == name:
                return automation
        return None

    @classmethod
    def summarize_all(cls) -> str:
        """Get summary of all automations"""
        return "\n".join([
            f"- {automation.name}: {automation.description}"
            for automation in cls._automations
        ])
```

### Registry Configuration (automations.yaml)

```yaml
# File: registries/config/automations.yaml

- name: "Data Analysis Automation"
  description: "Analyzes datasets and generates comprehensive insights"
  api_url_env: "DATA_ANALYSIS_API_URL"
  bearer_token_env: "DATA_ANALYSIS_BEARER_TOKEN"
  inputs:
    - name: "dataset"
      description: "Path or URL to the dataset to analyze"
      required: true
    - name: "analysis_type"
      description: "Type of analysis to perform (descriptive, predictive, prescriptive)"
      required: true

- name: "Report Generation Automation"
  description: "Generates formatted reports from analysis results"
  api_url_env: "REPORT_GEN_API_URL"
  bearer_token_env: "REPORT_GEN_BEARER_TOKEN"
  inputs:
    - name: "data"
      description: "Analysis data to include in report"
      required: true
    - name: "format"
      description: "Report format (pdf, html, markdown)"
      required: false
```

### Using Registries

```python
# In agents or prompts
from package_name.registries import AutomationRegistry

# Get all automations
automations = AutomationRegistry.get_all()

# Get summary for prompt
summary = AutomationRegistry.summarize_all()

# Use in agent prompt
prompt = f"""
Available tools:
{summary}

Select the appropriate tool for the task.
"""
```

### Key Requirements

1. **Static method**: Use `@staticmethod` for loader
2. **Class-level call**: Call with `.__func__()` at class level
3. **Path resolution**: Use `Path(__file__).parent` for relative paths
4. **Environment variables**: Load from env vars in config
5. **Type hints**: Proper typing for return values

---

## 15. Common Deployment Failures

### Issue 1: Module Not Found

**Error**: `ModuleNotFoundError: No module named 'package_name'`

**Causes**:
- Package name in `pyproject.toml` doesn't match directory under `src/`
- Package not installed (`uv sync` not run)
- Using relative imports instead of absolute

**Solutions**:
1. Verify `[project]` name in `pyproject.toml` matches `src/package_name/`
2. Run `uv sync` to install package
3. Change all imports to absolute: `from package_name.module import Class`
4. Ensure `__init__.py` exists in all directories

---

### Issue 2: Config File Not Found

**Error**: `FileNotFoundError: config/agents.yaml`

**Causes**:
- Config files not in correct location relative to crew.py
- Incorrect path in crew configuration

**Solutions**:
1. Verify directory structure:
   ```
   crews/crew_name/
   ├── crew.py
   └── config/
       ├── agents.yaml
       └── tasks.yaml
   ```
2. Use relative paths in crew: `agents_config = "config/agents.yaml"`
3. For services, use: `Path(__file__).parent / "config" / "file.yaml"`

---

### Issue 3: Environment Variables Not Loading

**Error**: `None` type or missing value for environment variables

**Causes**:
- `.env` file not in project root
- Environment variables not loaded
- Typo in variable names

**Solutions**:
1. Place `.env` in project root (same level as `pyproject.toml`)
2. For local testing, optionally use:
   ```python
   from dotenv import load_dotenv
   load_dotenv()
   ```
3. Verify variable names match exactly (case-sensitive)
4. Add validation:
   ```python
   if not os.getenv("API_KEY"):
       raise ValueError("API_KEY required")
   ```

---

### Issue 4: Tool Not Working in Agent

**Error**: Tool not available or not executing

**Causes**:
- Forgot to call `.tool()` method
- Tool not properly imported
- Tool configuration incomplete

**Solutions**:
1. Always call `.tool()` when passing to agents:
   ```python
   tools=[CustomTool().tool()]  # Not CustomTool()
   ```
2. Verify tool import: `from package_name.tools import CustomTool`
3. Check tool has environment variables it needs
4. Test tool initialization separately

---

### Issue 5: Pydantic Output Not Accessible

**Error**: `AttributeError` when accessing result fields

**Causes**:
- Not using `.pydantic` accessor
- Model not specified in `response_format`
- Incorrect field names

**Solutions**:
1. Access via `.pydantic`:
   ```python
   result = agent.kickoff(prompt, response_format=OutputModel)
   value = result.pydantic.field_name  # Use .pydantic
   ```
2. Verify `response_format` parameter is set
3. Check field names match Pydantic model definition

---

### Issue 6: YAML Syntax Errors

**Error**: `yaml.scanner.ScannerError` or key errors

**Causes**:
- Incorrect YAML indentation
- Missing colons
- Tabs instead of spaces

**Solutions**:
1. Use 2 spaces for indentation (never tabs)
2. Validate YAML syntax with online validator
3. Check structure:
   ```yaml
   key:
     role: >
       Multi-line
       string
     goal: >
       Another
   ```

---

### Issue 7: Circular Import Errors

**Error**: `ImportError: cannot import name 'X' from partially initialized module`

**Causes**:
- Modules importing from each other
- Importing from `__init__.py` within same package

**Solutions**:
1. Use absolute imports only
2. Move shared types to `types/` package
3. Avoid importing from `__init__.py` in same package
4. Restructure to break circular dependencies

---

### Issue 8: Entry Points Not Found

**Error**: `command not found: kickoff`

**Causes**:
- Package not installed
- Entry points not defined in `pyproject.toml`
- Virtual environment not activated

**Solutions**:
1. Run `uv sync` to install package and entry points
2. Verify `[project.scripts]` in `pyproject.toml`:
   ```toml
   [project.scripts]
   kickoff = "package_name.main:kickoff"
   ```
3. Check entry point format: `"package.module:function"`
4. Activate virtual environment if using one

---

### Issue 9: Type Hints Causing Errors

**Error**: `NameError` or `TypeError` related to type hints

**Causes**:
- Using `|` union syntax in Python < 3.10
- Forward references not resolved

**Solutions**:
1. For Python 3.10+, use modern syntax:
   ```python
   def func(value: str | None = None) -> list[str]:
       pass
   ```
2. For Python 3.9, use `typing`:
   ```python
   from typing import List, Optional
   
   def func(value: Optional[str] = None) -> List[str]:
       pass
   ```
3. Use `from __future__ import annotations` at top of file

---

### Issue 10: State Not Persisting in Flow

**Error**: State resets or doesn't persist

**Causes**:
- Missing `@persist()` decorator
- State model not properly defined
- Not modifying state correctly

**Solutions**:
1. Add `@persist()` decorator:
   ```python
   @persist()
   class ProjectFlow(Flow[FlowState]):
       pass
   ```
2. Modify state with attribute assignment:
   ```python
   self.state.field = value  # Correct
   ```
3. Verify FlowState model has all needed fields

---

## 16. Pre-Deployment Checklist

### Package Structure ✓

- [ ] Project root contains `pyproject.toml`
- [ ] Source code in `src/package_name/` directory
- [ ] Package name in `pyproject.toml` matches directory name
- [ ] All directories contain `__init__.py` files
- [ ] `__init__.py` files export classes with `__all__`

### Configuration Files ✓

- [ ] `pyproject.toml` has `[build-system]` with `hatchling`
- [ ] `pyproject.toml` has `[project.scripts]` entry points
- [ ] CrewAI version is pinned (e.g., `==1.4.1`)
- [ ] Python version is `>=3.10,<3.14`
- [ ] `.env` file exists in project root (not committed)
- [ ] `.gitignore` includes `.env`, `__pycache__`, etc.

### Imports ✓

- [ ] All imports use absolute paths (`from package_name.module import X`)
- [ ] No relative imports (`from .module` or `from ..package`)
- [ ] No direct module imports without package name
- [ ] CrewAI imports are correct and available

### Main Entry Point ✓

- [ ] `main.py` exists in `src/package_name/`
- [ ] Has shebang line: `#!/usr/bin/env python`
- [ ] Defines `kickoff()` function
- [ ] Defines `plot()` function
- [ ] Uses absolute imports from package
- [ ] Has `if __name__ == "__main__"` block

### Agents ✓

- [ ] Agent classes are in `agents/` directory
- [ ] Each agent has public execution method
- [ ] Uses `response_format=Model` for structured output
- [ ] Tools are passed with `.tool()` method call
- [ ] Agents properly imported in `agents/__init__.py`

### Crews ✓

- [ ] Crew classes use `@CrewBase` decorator
- [ ] Has `agents: List[BaseAgent]` type hint
- [ ] Has `tasks: List[Task]` type hint
- [ ] Config paths are relative to crew.py file
- [ ] YAML files exist in `config/` subdirectory
- [ ] Agent and task methods use decorators (`@agent`, `@task`, `@crew`)
- [ ] Crews properly imported in `crews/__init__.py`

### Tools ✓

- [ ] Tool classes have `.tool()` method that returns tool instance
- [ ] Tools are called with `.tool()` when passed to agents
- [ ] Environment variables are loaded for API keys
- [ ] Tools properly imported in `tools/__init__.py`

### Types/Models ✓

- [ ] All models inherit from `pydantic.BaseModel`
- [ ] FlowState model exists for flows
- [ ] Output models defined for agents/tasks
- [ ] Fields use `Field(...)` with descriptions
- [ ] Models properly imported in `types/__init__.py`

### Configuration (YAML) ✓

- [ ] `agents.yaml` exists in correct location
- [ ] `tasks.yaml` exists in correct location
- [ ] YAML uses spaces (not tabs) for indentation
- [ ] Agent keys match references in crew code
- [ ] Task keys match references in crew code
- [ ] Task `agent` field references valid agent key

### Environment Variables ✓

- [ ] `.env` file contains all required variables
- [ ] API keys are not hardcoded in source
- [ ] Variables are loaded with `os.getenv()`
- [ ] Required variables are validated
- [ ] `.env` is in `.gitignore`

### Installation & Testing ✓

- [ ] `uv sync` completes without errors
- [ ] Entry point commands work (`kickoff`, `plot`)
- [ ] No import errors when running
- [ ] No environment variable errors
- [ ] Tools can be initialized
- [ ] Agents can be instantiated
- [ ] Crews can be created

### Documentation ✓

- [ ] README.md explains project purpose
- [ ] README.md lists required environment variables
- [ ] README.md has setup/installation instructions
- [ ] README.md has usage examples

---

## Quick Reference Card

### Import Template

```python
# main.py and all internal modules
from package_name.agents import AgentClass
from package_name.crews import CrewClass
from package_name.types import FlowState, OutputModel
from package_name.tools import ToolClass
from package_name.services import ServiceClass
```

### __init__.py Template

```python
from .module_file import ClassName

__all__ = ["ClassName"]
```

### Tool Usage Template

```python
# Define tool
class CustomTool:
    def tool(self):
        return SomeCrewAITool(config={...})

# Use in agent
Agent(tools=[CustomTool().tool()])  # Call .tool()
```

### Agent Result Access Template

```python
result = agent.kickoff(prompt, response_format=OutputModel)
value = result.pydantic.field_name  # Use .pydantic
```

### Crew Kickoff Template

```python
crew_instance = CrewClass(param="value")
result = crew_instance.crew().kickoff(inputs={"key": "value"})
output = result.pydantic.field_name
```

### Environment Variable Template

```python
import os

class Service:
    _API_KEY = os.getenv("API_KEY")
    _BATCH_SIZE = int(os.getenv("BATCH_SIZE", "10"))
    
    def __init__(self):
        if not self._API_KEY:
            raise ValueError("API_KEY required")
```

---

## Troubleshooting Decision Tree

```
Import Error?
├─ Yes → Check package name matches src/ directory
│        Run uv sync
│        Use absolute imports
└─ No
   │
   Config File Not Found?
   ├─ Yes → Check file exists in config/ subdirectory
   │        Verify relative path in crew
   └─ No
      │
      Tool Not Working?
      ├─ Yes → Call .tool() method
      │        Check imports
      │        Verify env vars
      └─ No
         │
         Results Not Accessible?
         ├─ Yes → Use .pydantic accessor
         │        Check response_format set
         └─ No
            │
            Entry Point Not Found?
            ├─ Yes → Run uv sync
            │        Check [project.scripts]
            └─ No → Check other sections
```

---

## Final Notes

This document represents proven patterns from successful CrewAI Enterprise deployments. When troubleshooting:

1. **Start with structure**: Verify package structure and naming
2. **Check imports**: Ensure all imports are absolute
3. **Validate configuration**: Confirm pyproject.toml is correct
4. **Test incrementally**: Test each component separately
5. **Read error messages**: They usually point to the exact issue

When in doubt, compare your implementation against the templates and patterns in this document.

---

**Document Version**: 1.0  
**Last Updated**: 2025-11-11  
**Compatible With**: CrewAI 1.4.1+, Python 3.10-3.13